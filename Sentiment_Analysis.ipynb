{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpUh/xUGNWwEr0tQK51AKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishaDavda1411/Sentiment_Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment analysis of IMDB reviews\n",
        "We will start by importing the necessary libraries"
      ],
      "metadata": {
        "id": "qcriDpwHE4BD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kve7lh9n-AP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C41PiYnIqsSr",
        "outputId": "60e6f274-213b-4d0a-b1ff-3f74aaa5dffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the data files\n",
        "After importing the necessary libraries now we will read the data files we have two data files here\n"
      ],
      "metadata": {
        "id": "FaMjxWbrE_GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = r'/gdrive/MyDrive/Colab Notebooks/tutorial/Sentiment_Analysis/imdb_reviews.csv'\n",
        "file2 = r'/gdrive/MyDrive/Colab Notebooks/tutorial/Sentiment_Analysis/test_reviews.csv'"
      ],
      "metadata": {
        "id": "plu92lUhttF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first data file contains the imdb reviews and their corresponding sentiments which can be either positive or negative, we are going to use this file as our training data."
      ],
      "metadata": {
        "id": "O_QCBwXyFGIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_reviews = pd.read_csv(file1) #training\n",
        "test_reviews = pd.read_csv(file2) #testing"
      ],
      "metadata": {
        "id": "JyEbgOiCuPUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RB2q74ctulA3",
        "outputId": "b23f42e6-e2ed-4f37-c66f-f402cd73e667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews Sentiment\n",
              "0  <START this film was just brilliant casting lo...  positive\n",
              "1  <START big hair big boobs bad music and a gian...  negative\n",
              "2  <START this has to be one of the worst films o...  negative\n",
              "3  <START the <UNK> <UNK> at storytelling the tra...  positive\n",
              "4  <START worst mistake of my life br br i picked...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e158e391-c365-46e2-8ff7-aa69781cdde3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;START this film was just brilliant casting lo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;START big hair big boobs bad music and a gian...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;START this has to be one of the worst films o...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;START the &lt;UNK&gt; &lt;UNK&gt; at storytelling the tra...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;START worst mistake of my life br br i picked...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e158e391-c365-46e2-8ff7-aa69781cdde3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e158e391-c365-46e2-8ff7-aa69781cdde3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e158e391-c365-46e2-8ff7-aa69781cdde3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data\n",
        "We can not pass the string data to our model directly, so we need to transform the string data into integer format.For this we can map each distinct word as a distinct integer for eg.{'this':14 , 'the':1}.We already have a file that contains the mapping from words to integers so we are going to load that file.\n"
      ],
      "metadata": {
        "id": "9AFCswDhFNZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file3 = r'/gdrive/MyDrive/Colab Notebooks/tutorial/Sentiment_Analysis/word_indexes.csv'"
      ],
      "metadata": {
        "id": "pfi2retsusW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word index file contains mapping from words to integers."
      ],
      "metadata": {
        "id": "LSC7u2p2FUKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = pd.read_csv(file3)\n",
        "word_index.head(n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "B-tQ-xPhOFTP",
        "outputId": "96d0d158-e1f0-4d5e-fb7f-7a16719f7206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Words  Indexes\n",
              "0   tsukino    52009\n",
              "1   nunnery    52010\n",
              "2     sonja    16819\n",
              "3      vani    63954\n",
              "4     woods     1411\n",
              "5   spiders    16118\n",
              "6   hanging     2348\n",
              "7     woody     2292\n",
              "8  trawling    52011\n",
              "9    hold's    52012"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13caf9fd-e3d8-449e-982f-1d99eb512a1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Indexes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tsukino</td>\n",
              "      <td>52009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nunnery</td>\n",
              "      <td>52010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sonja</td>\n",
              "      <td>16819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vani</td>\n",
              "      <td>63954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>woods</td>\n",
              "      <td>1411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spiders</td>\n",
              "      <td>16118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hanging</td>\n",
              "      <td>2348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>woody</td>\n",
              "      <td>2292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>trawling</td>\n",
              "      <td>52011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>hold's</td>\n",
              "      <td>52012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13caf9fd-e3d8-449e-982f-1d99eb512a1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13caf9fd-e3d8-449e-982f-1d99eb512a1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13caf9fd-e3d8-449e-982f-1d99eb512a1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to convert the word_index dataframe into a python dictionary so that we can use it for converting our reviews from string to integer format."
      ],
      "metadata": {
        "id": "ocasqpBjFYgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = dict(zip(word_index.Words,word_index.Indexes))"
      ],
      "metadata": {
        "id": "VnvFTH4-OcdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"]=3"
      ],
      "metadata": {
        "id": "dGR_TvVFQIfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1JOiK17QgFM",
        "outputId": "91178c0c-ea70-49c6-8c4e-fe691dca91d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tsukino': 52009,\n",
              " 'nunnery': 52010,\n",
              " 'sonja': 16819,\n",
              " 'vani': 63954,\n",
              " 'woods': 1411,\n",
              " 'spiders': 16118,\n",
              " 'hanging': 2348,\n",
              " 'woody': 2292,\n",
              " 'trawling': 52011,\n",
              " \"hold's\": 52012,\n",
              " 'comically': 11310,\n",
              " 'localized': 40833,\n",
              " 'disobeying': 30571,\n",
              " \"'royale\": 52013,\n",
              " \"harpo's\": 40834,\n",
              " 'canet': 52014,\n",
              " 'aileen': 19316,\n",
              " 'acurately': 52015,\n",
              " \"diplomat's\": 52016,\n",
              " 'rickman': 25245,\n",
              " 'arranged': 6749,\n",
              " 'rumbustious': 52017,\n",
              " 'familiarness': 52018,\n",
              " \"spider'\": 52019,\n",
              " 'hahahah': 68807,\n",
              " \"wood'\": 52020,\n",
              " 'transvestism': 40836,\n",
              " \"hangin'\": 34705,\n",
              " 'bringing': 2341,\n",
              " 'seamier': 40837,\n",
              " 'wooded': 34706,\n",
              " 'bravora': 52021,\n",
              " 'grueling': 16820,\n",
              " 'wooden': 1639,\n",
              " 'wednesday': 16821,\n",
              " \"'prix\": 52022,\n",
              " 'altagracia': 34707,\n",
              " 'circuitry': 52023,\n",
              " 'crotch': 11588,\n",
              " 'busybody': 57769,\n",
              " \"tart'n'tangy\": 52024,\n",
              " 'burgade': 14132,\n",
              " 'thrace': 52026,\n",
              " \"tom's\": 11041,\n",
              " 'snuggles': 52028,\n",
              " 'francesco': 29117,\n",
              " 'complainers': 52030,\n",
              " 'templarios': 52128,\n",
              " '272': 40838,\n",
              " '273': 52031,\n",
              " 'zaniacs': 52133,\n",
              " '275': 34709,\n",
              " 'consenting': 27634,\n",
              " 'snuggled': 40839,\n",
              " 'inanimate': 15495,\n",
              " 'uality': 52033,\n",
              " 'bronte': 11929,\n",
              " 'errors': 4013,\n",
              " 'dialogs': 3233,\n",
              " \"yomada's\": 52034,\n",
              " \"madman's\": 34710,\n",
              " 'dialoge': 30588,\n",
              " 'usenet': 52036,\n",
              " 'videodrome': 40840,\n",
              " \"kid'\": 26341,\n",
              " 'pawed': 52037,\n",
              " \"'girlfriend'\": 30572,\n",
              " \"'pleasure\": 52038,\n",
              " \"'reloaded'\": 52039,\n",
              " \"kazakos'\": 40842,\n",
              " 'rocque': 52040,\n",
              " 'mailings': 52041,\n",
              " 'brainwashed': 11930,\n",
              " 'mcanally': 16822,\n",
              " \"tom''\": 52042,\n",
              " 'kurupt': 25246,\n",
              " 'affiliated': 21908,\n",
              " 'babaganoosh': 52043,\n",
              " \"noe's\": 40843,\n",
              " 'quart': 40844,\n",
              " 'kids': 362,\n",
              " 'uplifting': 5037,\n",
              " 'controversy': 7096,\n",
              " 'kida': 21909,\n",
              " 'kidd': 23382,\n",
              " \"error'\": 52044,\n",
              " 'neurologist': 52045,\n",
              " 'spotty': 18513,\n",
              " 'cobblers': 30573,\n",
              " 'projection': 9881,\n",
              " 'fastforwarding': 40845,\n",
              " 'sters': 52046,\n",
              " \"eggar's\": 52047,\n",
              " 'etherything': 52048,\n",
              " 'gateshead': 40846,\n",
              " 'airball': 34711,\n",
              " 'unsinkable': 25247,\n",
              " 'stern': 7183,\n",
              " \"cervi's\": 52049,\n",
              " 'dnd': 40847,\n",
              " 'dna': 11589,\n",
              " 'insecurity': 20601,\n",
              " \"'reboot'\": 52050,\n",
              " 'trelkovsky': 11040,\n",
              " 'jaekel': 52051,\n",
              " 'sidebars': 52052,\n",
              " \"sforza's\": 52053,\n",
              " 'distortions': 17636,\n",
              " 'mutinies': 52054,\n",
              " 'sermons': 30605,\n",
              " '7ft': 40849,\n",
              " 'boobage': 52055,\n",
              " \"o'bannon's\": 52056,\n",
              " 'populations': 23383,\n",
              " 'chulak': 52057,\n",
              " 'mesmerize': 27636,\n",
              " 'quinnell': 52058,\n",
              " 'yahoo': 10310,\n",
              " 'meteorologist': 52060,\n",
              " 'beswick': 42580,\n",
              " 'boorman': 15496,\n",
              " 'voicework': 40850,\n",
              " \"ster'\": 52061,\n",
              " 'blustering': 22925,\n",
              " 'hj': 52062,\n",
              " 'intake': 27637,\n",
              " 'morally': 5624,\n",
              " 'jumbling': 40852,\n",
              " 'bowersock': 52063,\n",
              " \"'porky's'\": 52064,\n",
              " 'gershon': 16824,\n",
              " 'ludicrosity': 40853,\n",
              " 'coprophilia': 52065,\n",
              " 'expressively': 40854,\n",
              " \"india's\": 19503,\n",
              " \"post's\": 34713,\n",
              " 'wana': 52066,\n",
              " 'wang': 5286,\n",
              " 'wand': 30574,\n",
              " 'wane': 25248,\n",
              " 'edgeways': 52324,\n",
              " 'titanium': 34714,\n",
              " 'pinta': 40855,\n",
              " 'want': 181,\n",
              " 'pinto': 30575,\n",
              " 'whoopdedoodles': 52068,\n",
              " 'tchaikovsky': 21911,\n",
              " 'travel': 2106,\n",
              " \"'victory'\": 52069,\n",
              " 'copious': 11931,\n",
              " 'gouge': 22436,\n",
              " \"chapters'\": 52070,\n",
              " 'barbra': 6705,\n",
              " 'uselessness': 30576,\n",
              " \"wan'\": 52071,\n",
              " 'assimilated': 27638,\n",
              " 'petiot': 16119,\n",
              " 'most\\x85and': 52072,\n",
              " 'dinosaurs': 3933,\n",
              " 'wrong': 355,\n",
              " 'seda': 52073,\n",
              " 'stollen': 52074,\n",
              " 'sentencing': 34715,\n",
              " 'ouroboros': 40856,\n",
              " 'assimilates': 40857,\n",
              " 'colorfully': 40858,\n",
              " 'glenne': 27639,\n",
              " 'dongen': 52075,\n",
              " 'subplots': 4763,\n",
              " 'kiloton': 52076,\n",
              " 'chandon': 23384,\n",
              " \"effect'\": 34716,\n",
              " 'snugly': 27640,\n",
              " 'kuei': 40859,\n",
              " 'welcomed': 9095,\n",
              " 'dishonor': 30074,\n",
              " 'concurrence': 52078,\n",
              " 'stoicism': 23385,\n",
              " \"guys'\": 14899,\n",
              " \"beroemd'\": 52080,\n",
              " 'butcher': 6706,\n",
              " \"melfi's\": 40860,\n",
              " 'aargh': 30626,\n",
              " 'playhouse': 20602,\n",
              " 'wickedly': 11311,\n",
              " 'fit': 1183,\n",
              " 'labratory': 52081,\n",
              " 'lifeline': 40862,\n",
              " 'screaming': 1930,\n",
              " 'fix': 4290,\n",
              " 'cineliterate': 52082,\n",
              " 'fic': 52083,\n",
              " 'fia': 52084,\n",
              " 'fig': 34717,\n",
              " 'fmvs': 52085,\n",
              " 'fie': 52086,\n",
              " 'reentered': 52087,\n",
              " 'fin': 30577,\n",
              " 'doctresses': 52088,\n",
              " 'fil': 52089,\n",
              " 'zucker': 12609,\n",
              " 'ached': 31934,\n",
              " 'counsil': 52091,\n",
              " 'paterfamilias': 52092,\n",
              " 'songwriter': 13888,\n",
              " 'shivam': 34718,\n",
              " 'hurting': 9657,\n",
              " 'effects': 302,\n",
              " 'slauther': 52093,\n",
              " \"'flame'\": 52094,\n",
              " 'sommerset': 52095,\n",
              " 'interwhined': 52096,\n",
              " 'whacking': 27641,\n",
              " 'bartok': 52097,\n",
              " 'barton': 8778,\n",
              " 'frewer': 21912,\n",
              " \"fi'\": 52098,\n",
              " 'ingrid': 6195,\n",
              " 'stribor': 30578,\n",
              " 'approporiately': 52099,\n",
              " 'wobblyhand': 52100,\n",
              " 'tantalisingly': 52101,\n",
              " 'ankylosaurus': 52102,\n",
              " 'parasites': 17637,\n",
              " 'childen': 52103,\n",
              " \"jenkins'\": 52104,\n",
              " 'metafiction': 52105,\n",
              " 'golem': 17638,\n",
              " 'indiscretion': 40863,\n",
              " \"reeves'\": 23386,\n",
              " \"inamorata's\": 57784,\n",
              " 'brittannica': 52107,\n",
              " 'adapt': 7919,\n",
              " \"russo's\": 30579,\n",
              " 'guitarists': 48249,\n",
              " 'abbott': 10556,\n",
              " 'abbots': 40864,\n",
              " 'lanisha': 17652,\n",
              " 'magickal': 40866,\n",
              " 'mattter': 52108,\n",
              " \"'willy\": 52109,\n",
              " 'pumpkins': 34719,\n",
              " 'stuntpeople': 52110,\n",
              " 'estimate': 30580,\n",
              " 'ugghhh': 40867,\n",
              " 'gameplay': 11312,\n",
              " \"wern't\": 52111,\n",
              " \"n'sync\": 40868,\n",
              " 'sickeningly': 16120,\n",
              " 'chiara': 40869,\n",
              " 'disturbed': 4014,\n",
              " 'portmanteau': 40870,\n",
              " 'ineffectively': 52112,\n",
              " \"duchonvey's\": 82146,\n",
              " \"nasty'\": 37522,\n",
              " 'purpose': 1288,\n",
              " 'lazers': 52115,\n",
              " 'lightened': 28108,\n",
              " 'kaliganj': 52116,\n",
              " 'popularism': 52117,\n",
              " \"damme's\": 18514,\n",
              " 'stylistics': 30581,\n",
              " 'mindgaming': 52118,\n",
              " 'spoilerish': 46452,\n",
              " \"'corny'\": 52120,\n",
              " 'boerner': 34721,\n",
              " 'olds': 6795,\n",
              " 'bakelite': 52121,\n",
              " 'renovated': 27642,\n",
              " 'forrester': 27643,\n",
              " \"lumiere's\": 52122,\n",
              " 'gaskets': 52027,\n",
              " 'needed': 887,\n",
              " 'smight': 34722,\n",
              " 'master': 1300,\n",
              " \"edie's\": 25908,\n",
              " 'seeber': 40871,\n",
              " 'hiya': 52123,\n",
              " 'fuzziness': 52124,\n",
              " 'genesis': 14900,\n",
              " 'rewards': 12610,\n",
              " 'enthrall': 30582,\n",
              " \"'about\": 40872,\n",
              " \"recollection's\": 52125,\n",
              " 'mutilated': 11042,\n",
              " 'fatherlands': 52126,\n",
              " \"fischer's\": 52127,\n",
              " 'positively': 5402,\n",
              " '270': 34708,\n",
              " 'ahmed': 34723,\n",
              " 'zatoichi': 9839,\n",
              " 'bannister': 13889,\n",
              " 'anniversaries': 52130,\n",
              " \"helm's\": 30583,\n",
              " \"'work'\": 52131,\n",
              " 'exclaimed': 34724,\n",
              " \"'unfunny'\": 52132,\n",
              " '274': 52032,\n",
              " 'feeling': 547,\n",
              " \"wanda's\": 52134,\n",
              " 'dolan': 33269,\n",
              " '278': 52136,\n",
              " 'peacoat': 52137,\n",
              " 'brawny': 40873,\n",
              " 'mishra': 40874,\n",
              " 'worlders': 40875,\n",
              " 'protags': 52138,\n",
              " 'skullcap': 52139,\n",
              " 'dastagir': 57599,\n",
              " 'affairs': 5625,\n",
              " 'wholesome': 7802,\n",
              " 'hymen': 52140,\n",
              " 'paramedics': 25249,\n",
              " 'unpersons': 52141,\n",
              " 'heavyarms': 52142,\n",
              " 'affaire': 52143,\n",
              " 'coulisses': 52144,\n",
              " 'hymer': 40876,\n",
              " 'kremlin': 52145,\n",
              " 'shipments': 30584,\n",
              " 'pixilated': 52146,\n",
              " \"'00s\": 30585,\n",
              " 'diminishing': 18515,\n",
              " 'cinematic': 1360,\n",
              " 'resonates': 14901,\n",
              " 'simplify': 40877,\n",
              " \"nature'\": 40878,\n",
              " 'temptresses': 40879,\n",
              " 'reverence': 16825,\n",
              " 'resonated': 19505,\n",
              " 'dailey': 34725,\n",
              " '2\\x85': 52147,\n",
              " 'treize': 27644,\n",
              " 'majo': 52148,\n",
              " 'kiya': 21913,\n",
              " 'woolnough': 52149,\n",
              " 'thanatos': 39800,\n",
              " 'sandoval': 35734,\n",
              " 'dorama': 40882,\n",
              " \"o'shaughnessy\": 52150,\n",
              " 'tech': 4991,\n",
              " 'fugitives': 32021,\n",
              " 'teck': 30586,\n",
              " \"'e'\": 76128,\n",
              " 'doesn’t': 40884,\n",
              " 'purged': 52152,\n",
              " 'saying': 660,\n",
              " \"martians'\": 41098,\n",
              " 'norliss': 23421,\n",
              " 'dickey': 27645,\n",
              " 'dicker': 52155,\n",
              " \"'sependipity\": 52156,\n",
              " 'padded': 8425,\n",
              " 'ordell': 57795,\n",
              " \"sturges'\": 40885,\n",
              " 'independentcritics': 52157,\n",
              " 'tempted': 5748,\n",
              " \"atkinson's\": 34727,\n",
              " 'hounded': 25250,\n",
              " 'apace': 52158,\n",
              " 'clicked': 15497,\n",
              " \"'humor'\": 30587,\n",
              " \"martino's\": 17180,\n",
              " \"'supporting\": 52159,\n",
              " 'warmongering': 52035,\n",
              " \"zemeckis's\": 34728,\n",
              " 'lube': 21914,\n",
              " 'shocky': 52160,\n",
              " 'plate': 7479,\n",
              " 'plata': 40886,\n",
              " 'sturgess': 40887,\n",
              " \"nerds'\": 40888,\n",
              " 'plato': 20603,\n",
              " 'plath': 34729,\n",
              " 'platt': 40889,\n",
              " 'mcnab': 52162,\n",
              " 'clumsiness': 27646,\n",
              " 'altogether': 3902,\n",
              " 'massacring': 42587,\n",
              " 'bicenntinial': 52163,\n",
              " 'skaal': 40890,\n",
              " 'droning': 14363,\n",
              " 'lds': 8779,\n",
              " 'jaguar': 21915,\n",
              " \"cale's\": 34730,\n",
              " 'nicely': 1780,\n",
              " 'mummy': 4591,\n",
              " \"lot's\": 18516,\n",
              " 'patch': 10089,\n",
              " 'kerkhof': 50205,\n",
              " \"leader's\": 52164,\n",
              " \"'movie\": 27647,\n",
              " 'uncomfirmed': 52165,\n",
              " 'heirloom': 40891,\n",
              " 'wrangle': 47363,\n",
              " 'emotion\\x85': 52166,\n",
              " \"'stargate'\": 52167,\n",
              " 'pinoy': 40892,\n",
              " 'conchatta': 40893,\n",
              " 'broeke': 41131,\n",
              " 'advisedly': 40894,\n",
              " \"barker's\": 17639,\n",
              " 'descours': 52169,\n",
              " 'lots': 775,\n",
              " 'lotr': 9262,\n",
              " 'irs': 9882,\n",
              " 'lott': 52170,\n",
              " 'xvi': 40895,\n",
              " 'irk': 34731,\n",
              " 'irl': 52171,\n",
              " 'ira': 6890,\n",
              " 'belzer': 21916,\n",
              " 'irc': 52172,\n",
              " 'ire': 27648,\n",
              " 'requisites': 40896,\n",
              " 'discipline': 7696,\n",
              " 'lyoko': 52964,\n",
              " 'extend': 11313,\n",
              " 'nature': 876,\n",
              " \"'dickie'\": 52173,\n",
              " 'optimist': 40897,\n",
              " 'lapping': 30589,\n",
              " 'superficial': 3903,\n",
              " 'vestment': 52174,\n",
              " 'extent': 2826,\n",
              " 'tendons': 52175,\n",
              " \"heller's\": 52176,\n",
              " 'quagmires': 52177,\n",
              " 'miyako': 52178,\n",
              " 'moocow': 20604,\n",
              " \"coles'\": 52179,\n",
              " 'lookit': 40898,\n",
              " 'ravenously': 52180,\n",
              " 'levitating': 40899,\n",
              " 'perfunctorily': 52181,\n",
              " 'lookin': 30590,\n",
              " \"lot'\": 40901,\n",
              " 'lookie': 52182,\n",
              " 'fearlessly': 34873,\n",
              " 'libyan': 52184,\n",
              " 'fondles': 40902,\n",
              " 'gopher': 35717,\n",
              " 'wearying': 40904,\n",
              " \"nz's\": 52185,\n",
              " 'minuses': 27649,\n",
              " 'puposelessly': 52186,\n",
              " 'shandling': 52187,\n",
              " 'decapitates': 31271,\n",
              " 'humming': 11932,\n",
              " \"'nother\": 40905,\n",
              " 'smackdown': 21917,\n",
              " 'underdone': 30591,\n",
              " 'frf': 40906,\n",
              " 'triviality': 52188,\n",
              " 'fro': 25251,\n",
              " 'bothers': 8780,\n",
              " \"'kensington\": 52189,\n",
              " 'much': 76,\n",
              " 'muco': 34733,\n",
              " 'wiseguy': 22618,\n",
              " \"richie's\": 27651,\n",
              " 'tonino': 40907,\n",
              " 'unleavened': 52190,\n",
              " 'fry': 11590,\n",
              " \"'tv'\": 40908,\n",
              " 'toning': 40909,\n",
              " 'obese': 14364,\n",
              " 'sensationalized': 30592,\n",
              " 'spiv': 40910,\n",
              " 'spit': 6262,\n",
              " 'arkin': 7367,\n",
              " 'charleton': 21918,\n",
              " 'jeon': 16826,\n",
              " 'boardroom': 21919,\n",
              " 'doubts': 4992,\n",
              " 'spin': 3087,\n",
              " 'hepo': 53086,\n",
              " 'wildcat': 27652,\n",
              " 'venoms': 10587,\n",
              " 'misconstrues': 52194,\n",
              " 'mesmerising': 18517,\n",
              " 'misconstrued': 40911,\n",
              " 'rescinds': 52195,\n",
              " 'prostrate': 52196,\n",
              " 'majid': 40912,\n",
              " 'climbed': 16482,\n",
              " 'canoeing': 34734,\n",
              " 'majin': 52198,\n",
              " 'animie': 57807,\n",
              " 'sylke': 40913,\n",
              " 'conditioned': 14902,\n",
              " 'waddell': 40914,\n",
              " '3\\x85': 52199,\n",
              " 'hyperdrive': 41191,\n",
              " 'conditioner': 34735,\n",
              " 'bricklayer': 53156,\n",
              " 'hong': 2579,\n",
              " 'memoriam': 52201,\n",
              " 'inventively': 30595,\n",
              " \"levant's\": 25252,\n",
              " 'portobello': 20641,\n",
              " 'remand': 52203,\n",
              " 'mummified': 19507,\n",
              " 'honk': 27653,\n",
              " 'spews': 19508,\n",
              " 'visitations': 40915,\n",
              " 'mummifies': 52204,\n",
              " 'cavanaugh': 25253,\n",
              " 'zeon': 23388,\n",
              " \"jungle's\": 40916,\n",
              " 'viertel': 34736,\n",
              " 'frenchmen': 27654,\n",
              " 'torpedoes': 52205,\n",
              " 'schlessinger': 52206,\n",
              " 'torpedoed': 34737,\n",
              " 'blister': 69879,\n",
              " 'cinefest': 52207,\n",
              " 'furlough': 34738,\n",
              " 'mainsequence': 52208,\n",
              " 'mentors': 40917,\n",
              " 'academic': 9097,\n",
              " 'stillness': 20605,\n",
              " 'academia': 40918,\n",
              " 'lonelier': 52209,\n",
              " 'nibby': 52210,\n",
              " \"losers'\": 52211,\n",
              " 'cineastes': 40919,\n",
              " 'corporate': 4452,\n",
              " 'massaging': 40920,\n",
              " 'bellow': 30596,\n",
              " 'absurdities': 19509,\n",
              " 'expetations': 53244,\n",
              " 'nyfiken': 40921,\n",
              " 'mehras': 75641,\n",
              " 'lasse': 52212,\n",
              " 'visability': 52213,\n",
              " 'militarily': 33949,\n",
              " \"elder'\": 52214,\n",
              " 'gainsbourg': 19026,\n",
              " 'hah': 20606,\n",
              " 'hai': 13423,\n",
              " 'haj': 34739,\n",
              " 'hak': 25254,\n",
              " 'hal': 4314,\n",
              " 'ham': 4895,\n",
              " 'duffer': 53262,\n",
              " 'haa': 52216,\n",
              " 'had': 69,\n",
              " 'advancement': 11933,\n",
              " 'hag': 16828,\n",
              " \"hand'\": 25255,\n",
              " 'hay': 13424,\n",
              " 'mcnamara': 20607,\n",
              " \"mozart's\": 52217,\n",
              " 'duffel': 30734,\n",
              " 'haq': 30597,\n",
              " 'har': 13890,\n",
              " 'has': 47,\n",
              " 'hat': 2404,\n",
              " 'hav': 40922,\n",
              " 'haw': 30598,\n",
              " 'figtings': 52218,\n",
              " 'elders': 15498,\n",
              " 'underpanted': 52219,\n",
              " 'pninson': 52220,\n",
              " 'unequivocally': 27655,\n",
              " \"barbara's\": 23676,\n",
              " \"bello'\": 52222,\n",
              " 'indicative': 13000,\n",
              " 'yawnfest': 40923,\n",
              " 'hexploitation': 52223,\n",
              " \"loder's\": 52224,\n",
              " 'sleuthing': 27656,\n",
              " \"justin's\": 32625,\n",
              " \"'ball\": 52225,\n",
              " \"'summer\": 52226,\n",
              " \"'demons'\": 34938,\n",
              " \"mormon's\": 52228,\n",
              " \"laughton's\": 34740,\n",
              " 'debell': 52229,\n",
              " 'shipyard': 39727,\n",
              " 'unabashedly': 30600,\n",
              " 'disks': 40404,\n",
              " 'crowd': 2293,\n",
              " 'crowe': 10090,\n",
              " \"vancouver's\": 56437,\n",
              " 'mosques': 34741,\n",
              " 'crown': 6630,\n",
              " 'culpas': 52230,\n",
              " 'crows': 27657,\n",
              " 'surrell': 53347,\n",
              " 'flowless': 52232,\n",
              " 'sheirk': 52233,\n",
              " \"'three\": 40926,\n",
              " \"peterson'\": 52234,\n",
              " 'ooverall': 52235,\n",
              " 'perchance': 40927,\n",
              " 'bottom': 1324,\n",
              " 'chabert': 53366,\n",
              " 'sneha': 52236,\n",
              " 'inhuman': 13891,\n",
              " 'ichii': 52237,\n",
              " 'ursla': 52238,\n",
              " 'completly': 30601,\n",
              " 'moviedom': 40928,\n",
              " 'raddick': 52239,\n",
              " 'brundage': 51998,\n",
              " 'brigades': 40929,\n",
              " 'starring': 1184,\n",
              " \"'goal'\": 52240,\n",
              " 'caskets': 52241,\n",
              " 'willcock': 52242,\n",
              " \"threesome's\": 52243,\n",
              " \"mosque'\": 52244,\n",
              " \"cover's\": 52245,\n",
              " 'spaceships': 17640,\n",
              " 'anomalous': 40930,\n",
              " 'ptsd': 27658,\n",
              " 'shirdan': 52246,\n",
              " 'obscenity': 21965,\n",
              " 'lemmings': 30602,\n",
              " 'duccio': 30603,\n",
              " \"levene's\": 52247,\n",
              " \"'gorby'\": 52248,\n",
              " \"teenager's\": 25258,\n",
              " 'marshall': 5343,\n",
              " 'honeymoon': 9098,\n",
              " 'shoots': 3234,\n",
              " 'despised': 12261,\n",
              " 'okabasho': 52249,\n",
              " 'fabric': 8292,\n",
              " 'cannavale': 18518,\n",
              " 'raped': 3540,\n",
              " \"tutt's\": 52250,\n",
              " 'grasping': 17641,\n",
              " 'despises': 18519,\n",
              " \"thief's\": 40931,\n",
              " 'rapes': 8929,\n",
              " 'raper': 52251,\n",
              " \"eyre'\": 27659,\n",
              " 'walchek': 52252,\n",
              " \"elmo's\": 23389,\n",
              " 'perfumes': 40932,\n",
              " 'spurting': 21921,\n",
              " \"exposition'\\x85\": 52253,\n",
              " 'denoting': 52254,\n",
              " 'thesaurus': 34743,\n",
              " \"shoot'\": 40933,\n",
              " 'bonejack': 49762,\n",
              " 'simpsonian': 52256,\n",
              " 'hebetude': 30604,\n",
              " \"hallow's\": 34744,\n",
              " 'desperation\\x85': 52257,\n",
              " 'incinerator': 34745,\n",
              " 'congratulations': 10311,\n",
              " 'humbled': 52258,\n",
              " \"else's\": 5927,\n",
              " 'trelkovski': 40848,\n",
              " \"rape'\": 52259,\n",
              " \"'chapters'\": 59389,\n",
              " '1600s': 52260,\n",
              " 'martian': 7256,\n",
              " 'nicest': 25259,\n",
              " 'eyred': 52262,\n",
              " 'passenger': 9460,\n",
              " 'disgrace': 6044,\n",
              " 'moderne': 52263,\n",
              " 'barrymore': 5123,\n",
              " 'yankovich': 52264,\n",
              " 'moderns': 40934,\n",
              " 'studliest': 52265,\n",
              " 'bedsheet': 52266,\n",
              " 'decapitation': 14903,\n",
              " 'slurring': 52267,\n",
              " \"'nunsploitation'\": 52268,\n",
              " \"'character'\": 34746,\n",
              " 'cambodia': 9883,\n",
              " 'rebelious': 52269,\n",
              " 'pasadena': 27660,\n",
              " 'crowne': 40935,\n",
              " \"'bedchamber\": 52270,\n",
              " 'conjectural': 52271,\n",
              " 'appologize': 52272,\n",
              " 'halfassing': 52273,\n",
              " 'paycheque': 57819,\n",
              " 'palms': 20609,\n",
              " \"'islands\": 52274,\n",
              " 'hawked': 40936,\n",
              " 'palme': 21922,\n",
              " 'conservatively': 40937,\n",
              " 'larp': 64010,\n",
              " 'palma': 5561,\n",
              " 'smelling': 21923,\n",
              " 'aragorn': 13001,\n",
              " 'hawker': 52275,\n",
              " 'hawkes': 52276,\n",
              " 'explosions': 3978,\n",
              " 'loren': 8062,\n",
              " \"pyle's\": 52277,\n",
              " 'shootout': 6707,\n",
              " \"mike's\": 18520,\n",
              " \"driscoll's\": 52278,\n",
              " 'cogsworth': 40938,\n",
              " \"britian's\": 52279,\n",
              " 'childs': 34747,\n",
              " \"portrait's\": 52280,\n",
              " 'chain': 3629,\n",
              " 'whoever': 2500,\n",
              " 'puttered': 52281,\n",
              " 'childe': 52282,\n",
              " 'maywether': 52283,\n",
              " 'chair': 3039,\n",
              " \"rance's\": 52284,\n",
              " 'machu': 34748,\n",
              " 'ballet': 4520,\n",
              " 'grapples': 34749,\n",
              " 'summerize': 76155,\n",
              " 'freelance': 30606,\n",
              " \"andrea's\": 52286,\n",
              " '\\x91very': 52287,\n",
              " 'coolidge': 45882,\n",
              " 'mache': 18521,\n",
              " 'balled': 52288,\n",
              " 'grappled': 40940,\n",
              " 'macha': 18522,\n",
              " 'underlining': 21924,\n",
              " 'macho': 5626,\n",
              " 'oversight': 19510,\n",
              " 'machi': 25260,\n",
              " 'verbally': 11314,\n",
              " 'tenacious': 21925,\n",
              " 'windshields': 40941,\n",
              " 'paychecks': 18560,\n",
              " 'jerk': 3399,\n",
              " \"good'\": 11934,\n",
              " 'prancer': 34751,\n",
              " 'prances': 21926,\n",
              " 'olympus': 52289,\n",
              " 'lark': 21927,\n",
              " 'embark': 10788,\n",
              " 'gloomy': 7368,\n",
              " 'jehaan': 52290,\n",
              " 'turaqui': 52291,\n",
              " \"child'\": 20610,\n",
              " 'locked': 2897,\n",
              " 'pranced': 52292,\n",
              " 'exact': 2591,\n",
              " 'unattuned': 52293,\n",
              " 'minute': 786,\n",
              " 'skewed': 16121,\n",
              " 'hodgins': 40943,\n",
              " 'skewer': 34752,\n",
              " 'think\\x85': 52294,\n",
              " 'rosenstein': 38768,\n",
              " 'helmit': 52295,\n",
              " 'wrestlemanias': 34753,\n",
              " 'hindered': 16829,\n",
              " \"martha's\": 30607,\n",
              " 'cheree': 52296,\n",
              " \"pluckin'\": 52297,\n",
              " 'ogles': 40944,\n",
              " 'heavyweight': 11935,\n",
              " 'aada': 82193,\n",
              " 'chopping': 11315,\n",
              " 'strongboy': 61537,\n",
              " 'hegemonic': 41345,\n",
              " 'adorns': 40945,\n",
              " 'xxth': 41349,\n",
              " 'nobuhiro': 34754,\n",
              " 'capitães': 52301,\n",
              " 'kavogianni': 52302,\n",
              " 'antwerp': 13425,\n",
              " 'celebrated': 6541,\n",
              " 'roarke': 52303,\n",
              " 'baggins': 40946,\n",
              " 'cheeseburgers': 31273,\n",
              " 'matras': 52304,\n",
              " \"nineties'\": 52305,\n",
              " \"'craig'\": 52306,\n",
              " 'celebrates': 13002,\n",
              " 'unintentionally': 3386,\n",
              " 'drafted': 14365,\n",
              " 'climby': 52307,\n",
              " '303': 52308,\n",
              " 'oldies': 18523,\n",
              " 'climbs': 9099,\n",
              " 'honour': 9658,\n",
              " 'plucking': 34755,\n",
              " '305': 30077,\n",
              " 'address': 5517,\n",
              " 'menjou': 40947,\n",
              " \"'freak'\": 42595,\n",
              " 'dwindling': 19511,\n",
              " 'benson': 9461,\n",
              " 'white’s': 52310,\n",
              " 'shamelessness': 40948,\n",
              " 'impacted': 21928,\n",
              " 'upatz': 52311,\n",
              " 'cusack': 3843,\n",
              " \"flavia's\": 37570,\n",
              " 'effette': 52312,\n",
              " 'influx': 34756,\n",
              " 'boooooooo': 52313,\n",
              " 'dimitrova': 52314,\n",
              " 'houseman': 13426,\n",
              " 'bigas': 25262,\n",
              " 'boylen': 52315,\n",
              " 'phillipenes': 52316,\n",
              " 'fakery': 40949,\n",
              " \"grandpa's\": 27661,\n",
              " 'darnell': 27662,\n",
              " 'undergone': 19512,\n",
              " 'handbags': 52318,\n",
              " 'perished': 21929,\n",
              " 'pooped': 37781,\n",
              " 'vigour': 27663,\n",
              " 'opposed': 3630,\n",
              " 'etude': 52319,\n",
              " \"caine's\": 11802,\n",
              " 'doozers': 52320,\n",
              " 'photojournals': 34757,\n",
              " 'perishes': 52321,\n",
              " 'constrains': 34758,\n",
              " 'migenes': 40951,\n",
              " 'consoled': 30608,\n",
              " 'alastair': 16830,\n",
              " 'wvs': 52322,\n",
              " 'ooooooh': 52323,\n",
              " 'approving': 34759,\n",
              " 'consoles': 40952,\n",
              " 'disparagement': 52067,\n",
              " 'futureistic': 52325,\n",
              " 'rebounding': 52326,\n",
              " \"'date\": 52327,\n",
              " 'gregoire': 52328,\n",
              " 'rutherford': 21930,\n",
              " 'americanised': 34760,\n",
              " 'novikov': 82199,\n",
              " 'following': 1045,\n",
              " 'munroe': 34761,\n",
              " \"morita'\": 52329,\n",
              " 'christenssen': 52330,\n",
              " 'oatmeal': 23109,\n",
              " 'fossey': 25263,\n",
              " 'livered': 40953,\n",
              " 'listens': 13003,\n",
              " \"'marci\": 76167,\n",
              " \"otis's\": 52333,\n",
              " 'thanking': 23390,\n",
              " 'maude': 16022,\n",
              " 'extensions': 34762,\n",
              " 'ameteurish': 52335,\n",
              " \"commender's\": 52336,\n",
              " 'agricultural': 27664,\n",
              " 'convincingly': 4521,\n",
              " 'fueled': 17642,\n",
              " 'mahattan': 54017,\n",
              " \"paris's\": 40955,\n",
              " 'vulkan': 52339,\n",
              " 'stapes': 52340,\n",
              " 'odysessy': 52341,\n",
              " 'harmon': 12262,\n",
              " 'surfing': 4255,\n",
              " 'halloran': 23497,\n",
              " 'unbelieveably': 49583,\n",
              " \"'offed'\": 52342,\n",
              " 'quadrant': 30610,\n",
              " 'inhabiting': 19513,\n",
              " 'nebbish': 34763,\n",
              " 'forebears': 40956,\n",
              " 'skirmish': 34764,\n",
              " 'ocassionally': 52343,\n",
              " \"'resist\": 52344,\n",
              " 'impactful': 21931,\n",
              " 'spicier': 52345,\n",
              " 'touristy': 40957,\n",
              " \"'football'\": 52346,\n",
              " 'webpage': 40958,\n",
              " 'exurbia': 52348,\n",
              " 'jucier': 52349,\n",
              " 'professors': 14904,\n",
              " 'structuring': 34765,\n",
              " 'jig': 30611,\n",
              " 'overlord': 40959,\n",
              " 'disconnect': 25264,\n",
              " 'sniffle': 82204,\n",
              " 'slimeball': 40960,\n",
              " 'jia': 40961,\n",
              " 'milked': 16831,\n",
              " 'banjoes': 40962,\n",
              " 'jim': 1240,\n",
              " 'workforces': 52351,\n",
              " 'jip': 52352,\n",
              " 'rotweiller': 52353,\n",
              " 'mundaneness': 34766,\n",
              " \"'ninja'\": 52354,\n",
              " \"dead'\": 11043,\n",
              " \"cipriani's\": 40963,\n",
              " 'modestly': 20611,\n",
              " \"professor'\": 52355,\n",
              " 'shacked': 40964,\n",
              " 'bashful': 34767,\n",
              " 'sorter': 23391,\n",
              " 'overpowering': 16123,\n",
              " 'workmanlike': 18524,\n",
              " 'henpecked': 27665,\n",
              " 'sorted': 18525,\n",
              " \"jōb's\": 52357,\n",
              " \"'always\": 52358,\n",
              " \"'baptists\": 34768,\n",
              " 'dreamcatchers': 52359,\n",
              " \"'silence'\": 52360,\n",
              " 'hickory': 21932,\n",
              " 'fun\\x97yet': 52361,\n",
              " 'breakumentary': 52362,\n",
              " 'didn': 15499,\n",
              " 'didi': 52363,\n",
              " 'pealing': 52364,\n",
              " 'dispite': 40965,\n",
              " \"italy's\": 25265,\n",
              " 'instability': 21933,\n",
              " 'quarter': 6542,\n",
              " 'quartet': 12611,\n",
              " 'padmé': 52365,\n",
              " \"'bleedmedry\": 52366,\n",
              " 'pahalniuk': 52367,\n",
              " 'honduras': 52368,\n",
              " 'bursting': 10789,\n",
              " \"pablo's\": 41468,\n",
              " 'irremediably': 52370,\n",
              " 'presages': 40966,\n",
              " 'bowlegged': 57835,\n",
              " 'dalip': 65186,\n",
              " 'entering': 6263,\n",
              " 'newsradio': 76175,\n",
              " 'presaged': 54153,\n",
              " \"giallo's\": 27666,\n",
              " 'bouyant': 40967,\n",
              " 'amerterish': 52371,\n",
              " 'rajni': 18526,\n",
              " 'leeves': 30613,\n",
              " 'macauley': 34770,\n",
              " 'seriously': 615,\n",
              " 'sugercoma': 52372,\n",
              " 'grimstead': 52373,\n",
              " \"'fairy'\": 52374,\n",
              " 'zenda': 30614,\n",
              " \"'twins'\": 52375,\n",
              " 'realisation': 17643,\n",
              " 'highsmith': 27667,\n",
              " 'raunchy': 7820,\n",
              " 'incentives': 40968,\n",
              " 'flatson': 52377,\n",
              " 'snooker': 35100,\n",
              " 'crazies': 16832,\n",
              " 'crazier': 14905,\n",
              " 'grandma': 7097,\n",
              " 'napunsaktha': 52378,\n",
              " 'workmanship': 30615,\n",
              " 'reisner': 52379,\n",
              " \"sanford's\": 61309,\n",
              " '\\x91doña': 52380,\n",
              " 'modest': 6111,\n",
              " \"everything's\": 19156,\n",
              " 'hamer': 40969,\n",
              " \"couldn't'\": 52382,\n",
              " 'quibble': 13004,\n",
              " 'socking': 52383,\n",
              " 'tingler': 21934,\n",
              " 'gutman': 52384,\n",
              " 'lachlan': 40970,\n",
              " 'tableaus': 52385,\n",
              " 'headbanger': 52386,\n",
              " 'spoken': 2850,\n",
              " 'cerebrally': 34771,\n",
              " \"'road\": 23493,\n",
              " 'tableaux': 21935,\n",
              " \"proust's\": 40971,\n",
              " 'periodical': 40972,\n",
              " \"shoveller's\": 52388,\n",
              " 'tamara': 25266,\n",
              " 'affords': 17644,\n",
              " 'concert': 3252,\n",
              " \"yara's\": 87958,\n",
              " 'someome': 52389,\n",
              " 'lingering': 8427,\n",
              " \"abraham's\": 41514,\n",
              " 'beesley': 34772,\n",
              " 'cherbourg': 34773,\n",
              " 'kagan': 28627,\n",
              " 'snatch': 9100,\n",
              " \"miyazaki's\": 9263,\n",
              " 'absorbs': 25267,\n",
              " \"koltai's\": 40973,\n",
              " 'tingled': 64030,\n",
              " 'crossroads': 19514,\n",
              " 'rehab': 16124,\n",
              " 'falworth': 52392,\n",
              " 'sequals': 52393,\n",
              " 'lillies': 21936,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define a function review_encoder that encodes the reviews into integer format according to the mapping specified by word_index file."
      ],
      "metadata": {
        "id": "uJBpJdRcFfqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def review_encoder(text):\n",
        "  arr = [word_index[word] for word in text]\n",
        "  return arr"
      ],
      "metadata": {
        "id": "k901LBbgQpfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the reviews from their corresponding sentiments so that we can preprocess the reviews and sentiments separately and then later pass it to our model."
      ],
      "metadata": {
        "id": "6xrVBlW3Fkv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,train_lables = imdb_reviews['Reviews'],imdb_reviews['Sentiment']\n",
        "test_data,test_lables = test_reviews['Reviews'],test_reviews['Sentiment']"
      ],
      "metadata": {
        "id": "sWES8hpKRHoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before transforming the reviews as integers we need to tokenize or split the review on the basis of whitespaces\n",
        "For eg.the string \"The movie was wonderful\" becomes [\"The\" , \"movie\" , \"was\" , \"wonderful\" ]."
      ],
      "metadata": {
        "id": "sneUY-3AFswY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.apply(lambda review:review.split())\n",
        "test_data =  test_data.apply(lambda review:review.split())"
      ],
      "metadata": {
        "id": "Qbu6imvXRkRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP4jfxl9W8zP",
        "outputId": "d72bd8f4-5ebb-47eb-b7a0-a55d4fa9aff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [<START, please, give, this, one, a, miss, br,...\n",
              "1        [<START, this, film, requires, a, lot, of, pat...\n",
              "2        [<START, many, animation, buffs, consider, <UN...\n",
              "3        [<START, i, generally, love, this, type, of, m...\n",
              "4        [<START, like, some, other, people, wrote, i'm...\n",
              "                               ...                        \n",
              "24995    [<START, the, book, is, better, than, the, fil...\n",
              "24996    [<START, the, largest, crowd, to, ever, see, a...\n",
              "24997    [<START, i, suppose, that, to, say, this, is, ...\n",
              "24998    [<START, in, love, 2, is, the, third, movie, i...\n",
              "24999    [<START, a, good, ol', boy, film, is, almost, ...\n",
              "Name: Reviews, Length: 25000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have tokenized the reviews now we can apply the review_encoder function to each review and transform the reviews into integer format."
      ],
      "metadata": {
        "id": "Vl8PjN20Fyoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.apply(review_encoder)\n",
        "test_data = test_data.apply(review_encoder)"
      ],
      "metadata": {
        "id": "ei-FPBCpYUtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After transforming, our reviews are going to look like this."
      ],
      "metadata": {
        "id": "dtfdrrs3F21c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1LgfOGZZZ_F",
        "outputId": "2f7847f0-08f6-4be9-eb79-a601b9d091a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...\n",
              "1        [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...\n",
              "2        [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...\n",
              "3        [1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153,...\n",
              "4        [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...\n",
              "                               ...                        \n",
              "24995    [1, 14, 9, 6, 2758, 20, 21, 1517, 7, 2078, 5, ...\n",
              "24996    [1, 4679, 2784, 299, 6, 1042, 37, 80, 81, 233,...\n",
              "24997    [1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2,...\n",
              "24998    [1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8,...\n",
              "24999    [1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8...\n",
              "Name: Reviews, Length: 25000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to encode the sentiments and we are labeling the positive sentiment as 1 and negative sentiment as 0."
      ],
      "metadata": {
        "id": "udPnClAKF83h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentiments(sentiment):\n",
        "  if sentiment=='positive':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "train_lables = train_lables.apply(encode_sentiments)\n",
        "test_lables = test_lables.apply(encode_sentiments)\n"
      ],
      "metadata": {
        "id": "Xksm8svxZnhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before giving the review as an input to the model we need to perform following preprocessing steps:\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "*   The length of each review should be made equal for the model to be working correctly.\n",
        "\n",
        "*  We have chosen the length of each review to be 500. \n",
        "*     If the review is longer than 500 words we are going to cut the extra part of the review.\n",
        "\n",
        "\n",
        "*       If the review is contains less than 500 words we are going to pad the review with zeros to increase its length to 500.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NnRvFFgWGCKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)\n",
        "test_data=keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)"
      ],
      "metadata": {
        "id": "LSw4oCDHZnC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing completed"
      ],
      "metadata": {
        "id": "Twx3YrP_tYK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the model\n",
        "Our model is a neural network and it consits of the following layers : \n",
        "\n",
        "1.   one word embedding layer which creates word embeddings of length 16 from integer encoded review.\n",
        "2.  second layer is global average pooling layer which is used to prevent overfitting by reducing the number of parameters.\n",
        "\n",
        "1.   then a dense layer which has 16 hidden units and uses relu as activation function\n",
        "2.  the final layer is the output layer which uses sigmoid as activation function \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4oSszOLAuhHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([keras.layers.Embedding(10000,16,input_length=500),\n",
        "                         keras.layers.GlobalAveragePooling1D(),\n",
        "                         keras.layers.Dense(16,activation='relu'),\n",
        "                         keras.layers.Dense(1,activation='sigmoid')])\n",
        "\n",
        "'''We use a combination of random weights and rectified linear unit (ReLU) activation function \n",
        "to add a ReLU dense (ReDense) layer to the trained neural network such that it can achieve \n",
        "a lower training loss\n",
        "\n",
        "Sigmoid Function acts as an activation function in machine learning which is used to add \n",
        "non-linearity in a machine learning model, in simple words it decides which value to pass\n",
        " as output and what not to pass'''\n"
      ],
      "metadata": {
        "id": "gGbsLYU6ugIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "2a4b75e6-2f04-4474-cbc4-d3c6f54a871c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We use a combination of random weights and rectified linear unit (ReLU) activation function \\nto add a ReLU dense (ReDense) layer to the trained neural network such that it can achieve \\na lower training loss\\n\\nSigmoid Function acts as an activation function in machine learning which is used to add \\nnon-linearity in a machine learning model, in simple words it decides which value to pass\\n as output and what not to pass'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#compiling the model\n",
        "\n",
        "\n",
        "1.   Adam is used as optimization function for our model.\n",
        "2.   Binary cross entropy loss function is used as loss function for the model.\n",
        "\n",
        "1.   Accuracy is used as the metric for evaluating the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zCDIUltjGP0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iwt1rjCctMWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step we are going to train the model on our downloaded IMDB dataset."
      ],
      "metadata": {
        "id": "I3dPiNIbGWqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history =  model.fit(train_data,train_lables,epochs=30,batch_size=512,validation_data=(test_data,test_lables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0-S4kcFv7iD",
        "outputId": "23f71899-f23a-4012-b820-d9f0a16eecb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "49/49 [==============================] - 3s 41ms/step - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6897 - val_accuracy: 0.6697\n",
            "Epoch 2/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.6830 - accuracy: 0.6908 - val_loss: 0.6750 - val_accuracy: 0.7193\n",
            "Epoch 3/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.6580 - accuracy: 0.7364 - val_loss: 0.6432 - val_accuracy: 0.7631\n",
            "Epoch 4/30\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 0.6137 - accuracy: 0.7852 - val_loss: 0.5947 - val_accuracy: 0.7890\n",
            "Epoch 5/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.5561 - accuracy: 0.8144 - val_loss: 0.5396 - val_accuracy: 0.8104\n",
            "Epoch 6/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.4951 - accuracy: 0.8420 - val_loss: 0.4862 - val_accuracy: 0.8328\n",
            "Epoch 7/30\n",
            "49/49 [==============================] - 2s 37ms/step - loss: 0.4394 - accuracy: 0.8606 - val_loss: 0.4428 - val_accuracy: 0.8438\n",
            "Epoch 8/30\n",
            "49/49 [==============================] - 2s 37ms/step - loss: 0.3934 - accuracy: 0.8723 - val_loss: 0.4064 - val_accuracy: 0.8552\n",
            "Epoch 9/30\n",
            "49/49 [==============================] - 2s 36ms/step - loss: 0.3567 - accuracy: 0.8816 - val_loss: 0.3779 - val_accuracy: 0.8630\n",
            "Epoch 10/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.3276 - accuracy: 0.8900 - val_loss: 0.3577 - val_accuracy: 0.8670\n",
            "Epoch 11/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.3047 - accuracy: 0.8956 - val_loss: 0.3426 - val_accuracy: 0.8698\n",
            "Epoch 12/30\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 0.2855 - accuracy: 0.9013 - val_loss: 0.3288 - val_accuracy: 0.8745\n",
            "Epoch 13/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.2693 - accuracy: 0.9068 - val_loss: 0.3218 - val_accuracy: 0.8736\n",
            "Epoch 14/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.2556 - accuracy: 0.9108 - val_loss: 0.3110 - val_accuracy: 0.8791\n",
            "Epoch 15/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.2433 - accuracy: 0.9166 - val_loss: 0.3051 - val_accuracy: 0.8798\n",
            "Epoch 16/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.2323 - accuracy: 0.9193 - val_loss: 0.3015 - val_accuracy: 0.8800\n",
            "Epoch 17/30\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 0.2230 - accuracy: 0.9230 - val_loss: 0.2956 - val_accuracy: 0.8832\n",
            "Epoch 18/30\n",
            "49/49 [==============================] - 2s 37ms/step - loss: 0.2136 - accuracy: 0.9264 - val_loss: 0.2935 - val_accuracy: 0.8831\n",
            "Epoch 19/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.2052 - accuracy: 0.9298 - val_loss: 0.2901 - val_accuracy: 0.8849\n",
            "Epoch 20/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1980 - accuracy: 0.9318 - val_loss: 0.2881 - val_accuracy: 0.8854\n",
            "Epoch 21/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1909 - accuracy: 0.9351 - val_loss: 0.2888 - val_accuracy: 0.8850\n",
            "Epoch 22/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1853 - accuracy: 0.9372 - val_loss: 0.2859 - val_accuracy: 0.8865\n",
            "Epoch 23/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1787 - accuracy: 0.9400 - val_loss: 0.2865 - val_accuracy: 0.8864\n",
            "Epoch 24/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1730 - accuracy: 0.9420 - val_loss: 0.2865 - val_accuracy: 0.8860\n",
            "Epoch 25/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.1676 - accuracy: 0.9444 - val_loss: 0.2861 - val_accuracy: 0.8854\n",
            "Epoch 26/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1625 - accuracy: 0.9455 - val_loss: 0.2895 - val_accuracy: 0.8860\n",
            "Epoch 27/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.1578 - accuracy: 0.9477 - val_loss: 0.2890 - val_accuracy: 0.8863\n",
            "Epoch 28/30\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.1537 - accuracy: 0.9490 - val_loss: 0.2888 - val_accuracy: 0.8855\n",
            "Epoch 29/30\n",
            "49/49 [==============================] - 2s 38ms/step - loss: 0.1491 - accuracy: 0.9512 - val_loss: 0.2903 - val_accuracy: 0.8855\n",
            "Epoch 30/30\n",
            "49/49 [==============================] - 2s 37ms/step - loss: 0.1448 - accuracy: 0.9530 - val_loss: 0.2918 - val_accuracy: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be evaluating the loss and accuracy of our model on testing data."
      ],
      "metadata": {
        "id": "QT6XC01XGcuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_data,test_lables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKt4O3qgwh_R",
        "outputId": "4b7604da-b500-429a-f718-dbc85d0a0652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.2918 - accuracy: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see our model is giving an accuracy of 88.56% on the testing data."
      ],
      "metadata": {
        "id": "y765TzbOGh5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kgEcPw3zwy6L",
        "outputId": "19531348-52ae-4bc9-b2da-8c2022391224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews Sentiment\n",
              "0  <START please give this one a miss br br <UNK>...  negative\n",
              "1  <START this film requires a lot of patience be...  positive\n",
              "2  <START many animation buffs consider <UNK> <UN...  positive\n",
              "3  <START i generally love this type of movie how...  negative\n",
              "4  <START like some other people wrote i'm a die ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db4c6970-c604-4525-9b43-cc49400d74d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;START please give this one a miss br br &lt;UNK&gt;...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;START this film requires a lot of patience be...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;START many animation buffs consider &lt;UNK&gt; &lt;UN...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;START i generally love this type of movie how...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;START like some other people wrote i'm a die ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db4c6970-c604-4525-9b43-cc49400d74d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db4c6970-c604-4525-9b43-cc49400d74d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db4c6970-c604-4525-9b43-cc49400d74d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to take a random review from our test dataset and check wether our model produces correct output or not"
      ],
      "metadata": {
        "id": "fLIRPdKHGl32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.random.randint(1,1000)"
      ],
      "metadata": {
        "id": "1O2rzlWIw6G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_review = test_reviews.loc[index]\n",
        "print(user_review.Reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEJHnQSyCcna",
        "outputId": "024d7f2b-8a13-4c06-95a8-90edbd602972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START i acquired this film a couple of years ago and on trying to find some info about it i found that even the mighty imdb didn't have it listed that should have been all i needed to know br br with friends like these is an anthology that plays like a collection of second rate twilight zone outer limits episodes all linked together by a bus journey that never really seems to tie in with the rest of the film of the three stories the only one that i <UNK> any entertainment value from was the second episode in which a man of sorts grows out of the <UNK> in a guys <UNK> this episode wins points for a few spots of humour and it's bizarre premise other than that there is an episode with a talking car bland and <UNK> and an episode where a girl visits a very unique dating agency my dog guessed the ending of this one br br as has been mentioned in other comments the 18 rating is entirely <UNK> there is nothing to offend here if you're after a good horror anthology check out asylum or the <UNK> films instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the sentiment for the above review is positive, now we are going to take the integer format of this particular review which we already have in our preprocessed test data and then give it as an input to our model to check the prediction of our model."
      ],
      "metadata": {
        "id": "WY_kAYvZGyZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_review = test_data[index]\n",
        "user_review = np.array([user_review])\n",
        "if (model.predict(user_review) > 0.5).astype(\"int32\"):\n",
        "  print(\"positive sentiment\")\n",
        "else:\n",
        "  print(\"negative sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ij0KhQDbNs",
        "outputId": "c531c641-83f1-4cc7-c685-b37cda3fb3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see our model is now able to predict the sentiment of the review."
      ],
      "metadata": {
        "id": "9C-CCcd_G2u3"
      }
    }
  ]
}